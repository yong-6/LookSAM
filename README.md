# Towards Efficient and Scalable Sharpness-Aware Minimization

In this repo, we try to implement a novel algorithm LookSAM - that only periodically calculates the inner gradient ascent, to significantly reduce the additional training cost of SAM.

This paper also accepted by CVPR 2022. We are trying to clean the code and will release the code recently. If you need, you can directly send an email to liuyong@comp.nus.edu.sg
